{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2298f22-f12d-47c5-86d8-beb653c0baa1",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0f6e1f7-301c-4f07-abc5-45439aad39d7",
   "metadata": {},
   "source": [
    "Liner Regression:\n",
    "            *Process of estimating an unknown quantity(y) based on known ones(x)*\n",
    "            \"Both the variables x and y are numeric\"\n",
    "            Operations allowed (only 2): Scalar multiplication and Addition\n",
    "            Statictical techniqe as well as machine learning model\n",
    "            Statistical technique of correlation analysis\n",
    "# Correlation is not always Causation # * (x may cause y, but y may not cause x) *       \n",
    "\n",
    "Correlation Analysis: association between two sets of quantative data\n",
    "Regression Analysis: variation in one variable is explained by the variation of one or more variables.\n",
    "*Linear regression is the comparison of two values usually x and y and the consistent change between those values*\n",
    "y = 3x\n",
    "here, y is dependant variable,\n",
    "x is independant variable (there can be multiple independant variables e.g. x1, x2, etc)\n",
    "\n",
    "\n",
    "E.g.: \n",
    "Input : X and Y both numeric values\n",
    "Output: coefficients (slope) of X : m\n",
    "        and the (intercept) bias (constant value) : b\n",
    "\n",
    "        Y = m X + b\n",
    "\n",
    "        This is called as regression model: find slope(m) and intercept(b)\n",
    "\n",
    "Regression line: A straight line that attempts to predict the relationship between two varaibles."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b69912f2-3afe-4991-ae7c-4949e661afb3",
   "metadata": {},
   "source": [
    "Slope (m) : indicates the steepness of a line (angle of slope)\n",
    "Intercept (c) : indicates where the location where it meets the y-axis\n",
    "\n",
    "If the sploe is greater, the steepness of the line is greater and the rate of change is also greater\n",
    "\n",
    "if slope is +ve : it indicates the +ve trend(uphill)\n",
    "if slope is -ve : it indicates the -ve trend(downhill)\n",
    "if slope is zero : the regression line looks horizontal. X does not affect y.\n",
    "\n",
    "If intercept is +ve, it meets the y-axix in the +ve quadrant and \n",
    "if the intercept is -ve, it meets in the -ve quadrant."
   ]
  },
  {
   "cell_type": "raw",
   "id": "734c5e0a-e38b-4fc3-9554-2a1804c79ae6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95ac62f4-dbfd-42e8-9c2d-e950399aab8a",
   "metadata": {},
   "source": [
    "Math Behind Linear Regression:\n",
    "\n",
    "   1. Two point method:\n",
    "        slope m = change in y / change in x\n",
    "              m = y2-y1 / x2-x1            (take two points and find the value of m)\n",
    "\n",
    "        Also represented as RISE / RUN\n",
    " \n",
    "\n",
    "        we know,\n",
    "            y = m x + b                          - Regression Algorithm ( model )\n",
    "        so, \n",
    "            b = y - m x                     (take a point and find the value of b)\n",
    "\n",
    "\n",
    "        after getting the values, build the regression model:\n",
    "            y = m x + b\n",
    "\n",
    "        Now, predict the values using different values of given x and y and find the deviation(residual) from predicted model.\n",
    "        deviation (residual) = actual y - predicted y\n",
    "        If residual is 0 then the regression model is correct else there is some error.\n",
    "\n",
    "\n",
    "        *Calculate Xmean and Ymean, and at that point , my regression line should be passing through the mean point.*\n",
    "\n",
    "\n",
    "    Minimizing the error:\n",
    "\n",
    "   2. Least Square Regression method:\n",
    "            m = SUM[( X - Xmean ) * ( Y - Ymean )]   /    SUM( X - Xmean )**2 \n",
    "\n",
    "            b = Ymean - m * Xmean\n",
    "\n",
    "            y = m x + b\n",
    "\n",
    "        Now, predict the values using different values of given x and y and find the deviation(residual) from predicted model.\n",
    "\n",
    "        deviation (residual) = actual y - predicted y\n",
    "        sum(square residual)SSR = SUM(actual y - predicted y )**2\n",
    "\n",
    "        Here, the sum of the residuals is equal to ZERO, to avoid this we are going to take the square of it which would be neglecting the negative           sign and give us some values. (This would also be helpful for comparing it Two Point Slope Method.)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa3f0d-5343-49ac-beb2-4018dafb6657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4d9070de-850a-47c5-aee1-d755dd7c3d9d",
   "metadata": {},
   "source": [
    "Regression Performance Evaluation:\n",
    "\n",
    "    Evaluation Metrics:\n",
    "        1. Mean Absolute Error (MAE):\n",
    "                    Absolute: only positive (Modulus)\n",
    "                    Error: Residual\n",
    "\n",
    "                   MAE =  1   SUM | y - Y |                               here, y = Actual y and  Y = predicted Y and n = no. of records\n",
    "                         ---\n",
    "                          N\n",
    "\n",
    "\n",
    "\n",
    "        2. Mean Square Error (MSE):\n",
    "                    Square: ^2\n",
    "\n",
    "\n",
    "                   MSE =  1   SUM ( y - Y )^2                               here, y = Actual y and  Y = predicted Y and n = no. of records\n",
    "                         ---\n",
    "                          N\n",
    "\n",
    "         3. Root Mean Square Error (RMSE):\n",
    "                    Root = underRoot\n",
    "                    Square: ^2\n",
    "\n",
    "\n",
    "                   MSE =  1   SUM ( y - Y )                             here, y = Actual y and  Y = predicted Y and n = no. of records\n",
    "                         ---\n",
    "                          N\n",
    "\n",
    "\n",
    "Accuracy: 1 - error\n",
    "\n",
    "R^2 score is a metric that tells the performance of the regression model\n",
    "\n",
    "Rsquare (R^2) = 1  -  Sum Squared Regression (SSR)              1 -   SUM( yi - yi' )^2\n",
    "                      ----------------------------         =         -------------------\n",
    "                       Total Sum of Squares (SST)                     SUM ( yi - y')^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800624bd-1986-4c20-b4bc-43cd36ab2518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f8174-95ca-452c-875b-1e4de97a3180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184369b-4ce3-4f32-9a01-164229afc7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "63cef8fc-0aea-4c79-a7bc-b8aecf8e9425",
   "metadata": {},
   "source": [
    "Types of Regression:\n",
    "    1. Linear Regression  (straight line)\n",
    "        a. Simple Linear Regression   ( 1 dependable variable y and 1 independent variable x )\n",
    "        b. Multiple Linear Regression ( 1 dependable variable y and multiple independent variable x1, x2, x3, ... , xn )\n",
    "                    y = b0 + b1x1 + b2x2 + .... + abnxn        where b0 is intercept and a1, a2 are the coefficients(weights)\n",
    "                    Y = b0 + X . W(transpose)               here X or W any one should be transpose ( both cannot be columns)\n",
    "\n",
    "    2. Non-Linear Regression (curved path)\n",
    "        a. Polynomial Regression \n",
    "\n",
    "\n",
    "            TO BE CONTINUED IN NOTEBOOK.................................\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
